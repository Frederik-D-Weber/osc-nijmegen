---
title: "OSCN Open Science Survey"
output: html_document
---

```{r packages, warning=FALSE, include=FALSE}

library(readr)          # read csv file
library(tm)             # for text mining
library(SnowballC)      # for text stemming
library(wordcloud)      # word-cloud generator 
library(tidytext)       # (?)
library(RColorBrewer)   # color palettes
library(ggplot2)        # for plotting pretty plots
library(dplyr)          # for everything?
library(janitor)        # maybe
library(knitr)          # for displaying tables
library(tidyverse)
# devtools::install_github("jaredhuling/jcolors")
library(jcolors)
library(Hmisc)          ## for function "capitalize"
library(wesanderson)    ## For the best colour palettes --> based on wes anderson movies :-)
```

```{r root_setup, include = FALSE}

# set rootdir to where this script is (assuming in "repo-root/src")
knitr::opts_knit$set(root.dir = getwd())

```

```{r functions, include = FALSE}
# Function to copy janitor clean_names() function but now for factor levels
# https://stackoverflow.com/questions/47886409/r-is-there-a-function-to-clean-factor-levels-characters-columnwise-in-a-data-f
clean_vec <- function (x, refactor=FALSE) {
  require(magrittr, quietly=TRUE)
  if (!(is.character(x) || is.factor(x))) return(x)
  x_is_factor <- is.factor(x)
  old_names <- as.character(x)
  new_names <- old_names %>%
    gsub("'", "", .) %>%
    gsub("\"", "", .) %>%
    gsub("%", "percent", .) %>%
    gsub("^[ ]+", "", .) %>%
    make.names(.) %>%
    gsub("[.]+", "_", .) %>%
    gsub("[_]+", "_", .) %>%
    tolower(.) %>%
    gsub("_$", "", .)
  if (x_is_factor && refactor) factor(new_names) else new_names
}
```


```{r read_data, warning = FALSE, message = FALSE}
# assume 'data' folder in rootdir
quest_data <- read_csv("../data/open_scholarship_survey_responses.csv") 
```

```{r, tidy_data, include = FALSE}
quest_data <- clean_names(quest_data, case = "snake")  # low-case column names with underscores

# Rename some column names

bad2good <- list(
"what_main_keywords_do_you_associate_with_open_science"
  =  "keywords",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_data_sharing"
  = "data_sharing",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_code_sharing"
  = "code_sharing",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_resource_sharing_e_g_stimuli_material"
  = "resource_sharing",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_open_access_publishing"
 = "open_access",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_open_peer_review"
 = "open_review",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_open_educational_material"
 = "open_edu",
"how_important_do_you_believe_are_the_following_open_science_practices_in_your_field_developing_alternative_evaluation_system_e_g_alternative_to_impact_factor"
 = "alt_eval",
"have_you_ever_requested_data_materials_from_the_authors_of_a_paper"
 = "requested_data",
"if_yes_under_what_circumstances_have_you_requested_access_to_data_material"
 = "requested_why",
"how_did_the_authors_respond_to_your_request"
 = "requested_response",
"have_you_ever_practiced_any_of_the_following_check_whichever_applies"
 = "ever_practiced",
"what_do_you_see_as_the_greatest_barriers_to_implement_open_science_practices_in_your_workflow_mark_all_that_apply"
 = "barriers",
"how_can_we_support_you_to_do_more_open_science"
 = "support",
"what_is_your_preferred_format_of_information_exchange_regarding_open_science_practices"
= "format",
"do_you_have_any_other_comments_about_this_survey"
 = "comments"
)

badnames  <- names(bad2good)
goodnames <- paste(unlist(bad2good))

colnames(quest_data)[colnames(quest_data) %in% badnames] <- goodnames # set new names

quest_data$career_stage <- as.factor(quest_data$career_stage)

```

## Participant demographics

### Career stage
```{r demographics, echo = FALSE}
# Create a separate data frame (tibble)
career_stage <- as_tibble(sapply(quest_data$career_stage, tolower))

# Group participants' labels

# let's count these as PI or higher
pi_or_higher <- career_stage$value %in% 
                  c("professor", 
                  "ik heb geen idee wat pi is, maar ik ben hoogleraar",
                  "full professor",
                  "lecturer") # labels that can be counted as "PI or higher"

# these can be counted as "post-doctorals" (perhaps a more suitable label can be used)
non_tenure <- career_stage$value %in% 
              c("assistant professor",
                "assistant professor (temporary position)",
                "associate pi",
                "junior lecturer",
                "junior lecturer (niv 4)",
                "univeristair docent")

# change the selected labels
career_stage$value[pi_or_higher] <- "pi or higher"
career_stage$value[non_tenure] <- "post-doctoral researcher"

predefined <- c("pi or higher", "phd employee", "post-doctoral researcher",
                "student (bachelor's, master's)")
other      <- career_stage$value[(!career_stage$value %in% predefined)] # labels given by participants

# change the non-predefined labels as other
career_stage$value[career_stage$value %in% other] <- "other"

# compute counts
career_stage_freq <- career_stage %>%
                     group_by(value) %>%
                     summarise(counts = n())

## Plot the histogram
career_stage_freq %>%
  ggplot(aes(x = reorder(value, counts), y = counts)) +
  geom_bar(aes(fill = counts), stat = "identity") +
  geom_text(aes(label = counts), hjust = -0.5, size = 5) +
  coord_flip() + 
  theme_classic() +
  ylim(0,110) +
  labs(title="", x = "", y = "Count") + 
  theme(legend.position="none", 
        axis.text.x  = element_text(size=15,  color="#000000"),     
        axis.text.y  = element_text(size=15,  color="#000000"),       
        axis.title.x = element_text(size=15,  color="#000000"),
        axis.line.x  = element_line(size=1.3, color="#000000"),
        axis.line.y  = element_line(size=1.3, color="#000000"),
        panel.border = element_blank()) +
  scale_x_discrete(labels = c("student", "other", "post-doc", "PhD", "PI or higher"))

```

### Affiliation

To see participants' affiliations, first map different tokens for the same affiliation
to a single token (string). There will be some inappropriate input under affiliations
(e.g. "professor" etc.), exclude those. Finally, plot a histogram of affiliations
and include new labels into `quest_data` variable for further use if needed.

to-do:  
- finish grouping  
- extra preprocessing (if needed)  
- plot histogram  


```{r demographics_affiliation}

d <- tolower(quest_data$affiliation)   # put them all to lowercase to simplify grep searches
a <- d                                 # variable for new affiliations 

# find affiliation strings containing "donders" etc.
a[grep("(donders|dcc|dcn|dccn)", d)] <- "donders"   # donders institute
a[grep("(mpi|planck)", d)] <- "mpi"                 # max planck institute for psycholinguistics
a[grep("(umc|medical|medicine)", d)] <- "umc"       # university medical centre
a[grep("(faculty of science|fnwi)", d)] <- "fs"     # faculty of science
a[grep("(imr|management)", d)] <- "management"      # nijmegen school of management
a[grep("(bsi|behavioral|behavioural)", d)] <- "bsi" # behavioral science institute
a[grep("(imm|materials)", d)] <- "imm"              # institute for molecules and materials (faculty of science)
a[grep("(ster|law|rechten)", d)] <- "law"           # law faculty
a[grep("(icis|information sciences)", d)] <- "icis" # institute for computing and information sciences (faculty of science)
a[grep("(theology|ftr)", d)] <- "ftr"               # faculty of philosophy, theology, and religious studies
a[grep("(arts|letteren)", d)] <- "arts"             # faculty of arts
a[grep("(cls|language studies)", d)] <- "cls"       # centre for language studies (faculty of arts)

# ... TO BE CONTINUED :)

```

### Research field

Preprocessing needed as with affiliations ...

## Keywords

Make a wordcloud from the responses.
This link gives a tutorial how to use an R package for that
http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know

```{r word_cloud, warning = FALSE, message = FALSE}

t <- as_tibble(quest_data$keywords) # create a short-name variable

# distinguish those who used commas vs. semicolons as separators
commasep <- grepl(",", t$value)
semicsep <- grepl(";", t$value)

# encode keyword phrases per subject as individual strings (not single char)
words1 <- sapply(t[commasep,], FUN=strsplit, split=",", USE.NAMES=FALSE) %>%
         unlist() %>%
         tolower() %>%    # make it lowercase
         as_tibble()

# same, but for semicolons
words2 <- sapply(t[semicsep,], FUN=strsplit, split=";", USE.NAMES=FALSE) %>%
         unlist() %>%
         tolower() %>%    # make it lowercase
         as_tibble()

words <- rbind(words1, words2) # put together

# trim trailing whitespaces
words <- sapply(words, FUN=trimws, USE.NAMES = FALSE) %>%
         as_tibble()


kable(head(words)) # already sufficiently clean data for a word cloud

## Cleaning the text: add underscore to bin the words properly
docs <- clean_vec(factor(words$value), TRUE)
docs <- Corpus(VectorSource(docs)) # VectorSource() function creates a corpus of character vectors

docs <- tm_map(docs, content_transformer(function(x) gsub(x, pattern = "pre_registration", replacement = "preregistration")))
docs <- tm_map(docs, removeWords, c("and")) 

## Build a term-document matrix
dtm <- TermDocumentMatrix(docs)
dtm <- as.matrix(dtm)
dtm <- sort(rowSums(dtm),decreasing=TRUE)
dtm <- data.frame(word = names(dtm),freq=dtm)
head(dtm, 10)

## Remove the underscore again for plotting
dtm$word <- as.factor(sub("_", " ", dtm$word))
dtm$word <- as.factor(sub("_", " ", dtm$word)) ## repeat for multiple underscores

dtm$word <- capitalize(as.character(dtm$word))

## Generate wordcloud
set.seed(1234)
wordcloud(words = dtm$word, freq = dtm$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=wes_palette("Zissou1"))

```


### Components of OS practices

```{r data_sharing}

# create a separate dataframe
dat <- quest_data
dat$career_stage <- career_stage$value  # use cleaned/grouped career_stage values

# define needed columns and order the levels
col2row <- c("data_sharing", "code_sharing", "resource_sharing", "open_access", "open_review", "open_edu", "alt_eval")
ordered_levels = c("Not at all important", "Mostly not important", "No idea", "Somewhat important", "Extremely important", 
                   "I don't know what this is")

# perform selection and convert to long format (make 'aspect' variable)
long <- select(dat, career_stage, col2row) %>%
        gather(component, value, -c(career_stage))

# order levels of 'value' variable for histogram
long$value <- factor(long$value, levels = ordered_levels)

# this df can be used for histograms e.g.:

# too busy raw histogram
ggplot(data = long, mapping = aes(x = value, fill = component)) +
  geom_histogram(stat = "count", position = "dodge")

# facet by aspect (very raw)
ggplot(data = long, mapping = aes(x = value, fill = career_stage)) +
  geom_histogram(stat = "count", position = "dodge") +
  facet_wrap(~ component)


```

